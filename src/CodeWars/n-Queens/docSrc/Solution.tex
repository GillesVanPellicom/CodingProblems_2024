\documentclass{article}

% packages
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{titlesec}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{bbm}
\usepackage{url}
\usepackage[colorlinks=true, linkcolor=blue, urlcolor=blue, citecolor=blue]{hyperref}
\usepackage[a4paper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% codeblock styling
\lstset{
    basicstyle=\ttfamily\small, 
    keywordstyle=\color{black}, 
    commentstyle=\color{black},
    stringstyle=\color{black}, 
    numbers=left, 
    numberstyle=\tiny\color{black},
    stepnumber=1,
    frame=none, 
    breaklines=true, 
    language=C++
}

% paragraph styling
\setcounter{secnumdepth}{4}
\titleformat{\paragraph}
{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
\titlespacing*{\paragraph}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}
\setlength{\parindent}{0pt}
\setlength{\parskip}{1em}

% Preamble
\title{Heuristic Approach for Efficiently Solving Large-Scale n-Queens Problems with a Pre-Specified Mandatory Queen}
\author{Gilles Van pellicom}
\date{8 September 2024}

\begin{document}

\maketitle

\begin{abstract}
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{1em}
    The n-Queens problem tasks us with placing \(n\) queens on an \(n \times n\) chessboard such that no two queens attack each other.
    This includes ensuring no queens share the same row, column, diagonal or anti-diagonal. Additionally, to make this version of the problem more challenging,
    one queen's position is fixed.
    The mandatory queen placement introduces challenges in certain cases, leading to unsolvable configurations, which are also handled.
    This explanation explores different approaches to solving the n-Queens problem for varying board sizes up to \(n = 1000\).

    This explanation recognizes the broad scope of the material used and as such will include links to articles explaining specific concepts
    each time they are initially mentioned.
    These links are embedded in the text for the digital version but can also be found in the references section on the last page if you are reading the printed version.
\end{abstract}

\clearpage

% table of contents with black hyperlinks
{
    \hypersetup{linkcolor=black}
    \tableofcontents
}

\clearpage

\section{Introduction}
This problem is classically used in computer science to teach beginners the concept of
\href{https://en.wikipedia.org/wiki/Backtracking}{algorithmic backtracking}\textsuperscript{[1]}.
Although this approach is quite intuitive, solving the problem this way carries a horribly bad
\href{https://en.wikipedia.org/wiki/Time_complexity}{time complexity}\textsuperscript{[2]} of \(\mathcal{O}(n!)\).
This is acceptable for small \(n\), but since in this version of the problem \(0 \leq n \leq 1000\), this approach is not feasible.

E.g. even for \(n = 20 \implies \mathcal{O}(20!) \approx 2.432902 \cdot 10^{18}\) iterations.

There are quite a few ways of optimizing backtracking for the n-Queens problem, such as
\href{https://en.wikipedia.org/wiki/Decision_tree_pruning}{pruning}\textsuperscript{[3]},
\href{https://en.wikipedia.org/wiki/Memoization}{memoization}\textsuperscript{[4]}, and
\href{https://www.khoury.northeastern.edu/home/wahl/Publications/ew05b.pdf}{symmetry reduction}\textsuperscript{[5]}.
However, even with these optimizations, the average time complexity will still be a not very spectacular
\(\mathcal{O}(c^n)\) where \(c \approx [1.5; 2]\) and worst case \(\mathcal{O}(n \cdot 2^n)\). Again, this makes large \(n\) infeasible.
Because of these initial observations, I realised I required a different approach.

\section{Attempt One: Simulated Annealing}
\href{https://en.wikipedia.org/wiki/Simulated_annealing}{Simulated annealing}\textsuperscript{[6]} (SA) is an example of a
\href{https://en.wikipedia.org/wiki/Randomized_algorithm}{randomized algorithm}\textsuperscript{[7]}.
SA is a \href{https://en.wikipedia.org/wiki/Metaheuristic}{metaheuristic}\textsuperscript{[8]} technique inspired by
\href{https://en.wikipedia.org/wiki/Metallurgy#:~:text=Metallurgy%20is%20a%20domain%20of,which%20are%20known%20as%20alloys.}{metallurgy}\textsuperscript{[9]} where controlled 
\href{https://en.wikipedia.org/wiki/Entropy}{entropy}\textsuperscript{[10]} is utilised to selectively temper out defects and converge to an optimal solution. For a given
\href{https://en.wikipedia.org/wiki/Constraint_satisfaction_problem}{CSP}\textsuperscript{[11]}, such as in this case the n-Queens problem, SA is able to relatively quickly converge,
especially compared to a \href{https://en.wikipedia.org/wiki/Brute-force_attack}{brute-force}\textsuperscript{[12]} approach.

\subsection{Simulated Annealing, Generalised}
Viewed at a high level, SA works as follows: The goal is to bring the system (in this case n-Queens), from an arbitrary initial state,
to a perfect state with the minimum possible energy level (conflicts).
To utilise simulated annealing two main functions have to be defined:

\begin{itemize}
    \item \textbf{Neighbor Function}: This function takes the current state of the system, makes a small and random change, and returns the resulting state which we call a neighbor.
    \item \textbf{Energy Function}: This function computes the energy of a given state, which in this context corresponds to the number of conflicts between queens.
\end{itemize}

The algorithm starts with a specific temperature, which cools by a specified factor each iteration.
The temperature controls the likelihood of a counter-productive neighbor being accepted.
This is done in order to the sufficiently traverse the solution space in the hopes of quickly arriving at an optimal solution.

\subsubsection{Notation}

\begin{itemize}
    \item \(\boldsymbol{T}\): current temperature and initially starting temperature.
    \item \(\boldsymbol{T_{\mathbf{min}}}\): minimum temperature.
    \item \(\boldsymbol{\alpha}\): cooling factor.
    \item \(\boldsymbol{E_{\mathbf{current}}}\): current board energy.
    \item \(\boldsymbol{E_{\mathbf{neighbor}}}\): neighbor board energy.
    \item \(\boldsymbol{\Delta E} = E_{\text{neighbor}} - E_{\text{current}}\)
\end{itemize}

\subsection{Main algorithm}

Each iteration, \(T\) is multiplied by \(\alpha\), \(T \coloneqq T \cdot \alpha\),
to cool the temperature and lower the chances of accepting a worse neighbor as the algorithm gets closer to a solution. More specifically:

\[
    \text{If } \left(\Delta E < 0 \lor \exp\left(\frac{-\Delta E}{T}\right) > x \text{ where } \{x \in \mathbb{R} \mid 0 \leq x \leq 1 \}\right)
\]
\[
    \text{Then accept the neighbor.}
\]

Where \( \exp(a) = e^a \), \( e \) is \href{https://en.wikipedia.org/wiki/E_(mathematical_constant)}{Euler's number}\textsuperscript{[13]}
and \( x \) is randomized each iteration within given constraints.

To elaborate on the acceptance criteria, there are basically three paths leading to two outcomes:

\begin{enumerate}
    \item \(\boldsymbol{\Delta E < 0}\). If the difference in energy is negative, the neighbor is better. Accept the neighbor.
    \item \(\boldsymbol{\exp\left(\frac{-\Delta E}{T}\right) > x \textbf{ where } \{x \in \mathbbm{R} \mid 0 \leq x \leq 1 \}}\).
          If the first criterion is not met, calculate the chance this neighbor will be accepted based on the difference in energy and
          the current temperature. If that chance is greater than a randomly generated number \(x\) between \(0\) and \(1\), accept the neighbor.
    \item \textbf{If both criteria fail}, discard the neighbor.
\end{enumerate}

\subsection{Critical Issues}
Unfortunately there are two main glaring issues with using simulated annealing specifically for n-Queens with large \(n\), and in general for CSP's where a 100\% accurate solution is expected.

\subsubsection{Critical Issue 1: Stagnation}
SA has the tendancy to stagnate. This means the algorithm gets stuck on almost-but-not-really optimal solutions (local minima),
usually within \(2-3\%\) of an optimal \(E = 0\) solution.
This is acceptable for some problems such as the \href{https://en.wikipedia.org/wiki/Travelling_salesman_problem}{Travelling Salesman Problem}\textsuperscript{[14]},
where complete accuracy isn't a requirement for the solution to be practical, but that isn't the case for n-Queens.

This could be solved by implementing a stagnation detection and resolving algorithm.
The problem with doing this is that you have to define when something counts as stagnation,
what actions to take when stagnation has been detected, how much action to take and when to take it.
Meaning quite a few new variables which need adjusting would have to be introduced on top of the very sensitive annealing variables.

These variables also can't be constant and have to be in function of \(n\).

Profiling and solving this very delicate balancing act is a large time investment with no real guarantee of success in the end,
especially when combined with the next issue.

\subsubsection{Critical Issue 2: Convergence}
As previously stated, SA is efficient at getting close to an optimal solution.
Actually converging from a board with e.g. \(E=8\) to \(E=0\) is a different story.
This isn't very efficient since SA is basically a random number generator with no real idea of what it's working toward.
The amount of time required to fully converge gets very steep as \(n \to 1000\).

\subsection{Conclusion}
Because of the two major issues stated above, SA was deemed to be a poor fit for this particular problem.

However, the concept of dynamically adjusting agressiveness of action based on how close
to a solution the algorithm currently is, was implemented in the final solution.

\section{Attempt Two: Min-Conflicts}
\href{https://en.wikipedia.org/wiki/Min-conflicts_algorithm}{Min-conflicts}\textsuperscript{[15]}
is a heuristics-based search algorithm which shines in quickly converging from a semi-high energy state to a perfect state (\(E = 0\)).

The algorithm creates a list of all queens with the very highest \(E\) values (most conflicts),
picks out one of the queens from that list at random and places it in a new location
which has been calculated to have lowest possible \(E\) value out of all moves which can be made with that queen.
If more than one lowest energy location exists, pick one at random as to more effectively explore the entire solution space.

This approach is much more efficient and simpler for this particular problem compared to SA since there aren't any tempermental variables to tangle with.

\subsection{Critical Issues}
Even though this approach should be much better suited to this problem, there are still issues.

\subsubsection{Critical Issue 1: Stagnation}
As with SA, stagnation is a big issue. Especially with small \(n<10\), where this algorithm has a tendancy to take tens of minutes
over something which could conceivably be calculated in a few milliseconds.
The algorithm stagnates about 50\% of the time for small \(n\).
Min-conflicts doesn't have very sensitive variables as with SA,
so I felt much more comfortable putting in the time of running test-suites to find the optimal formulae to calculate the variables
in order to fine-tune a sophisticated stagnation D/R (detection and resolution) system.

\paragraph{Notation}
\begin{itemize}

    \item \(iterationCount\): amount of times the algorithm has looped.
    \item \(stagnationCheckInterval\): amount of iterations between checks, calculated as \(10n\).
          \newline \((stagnationCheckInterval \in \mathbb{Z}^+)\).
          \newline In other words, every \(iterationCount \equiv 0 \pmod{10n}\), stagnation D/R runs.
\end{itemize}

\paragraph{Solution}
To resolve stagnation, the computer first has to be able to detect stagnation. For this purpose stagnation has to be defined, and I have defined it as such:
"if three samples of the board's total energy, taken at specified points within $stagnationCheckInterval$,
and the current total energy are all equal, the board has stagnated".

The algorithm periodically takes energy samples of the entire board.
Here are the criteria for when to take each sample:

\begin{itemize}

    \item \(\mathbf{S_1}\): at \(stagnationCheckInterval\)
    \item \(\mathbf{S_2}\): at \( \left\lfloor \frac{stagnationCheckInterval}{1.5} \right\rfloor\)
    \item \(\mathbf{S_3}\): at \( \left\lfloor \frac{stagnationCheckInterval}{3.0} \right\rfloor\)
\end{itemize}

When dividing as with $S_2$ and $S_3$, the $floor()$ function is utilised so that modulo checks with
\newline $iterationCount$, which is $\mathbb{Z}^+$, don't consistently fail.

By using tri-sampling instead of only one sample, the chance of false positives is lowered significantly.
Also the fact that in this implementation all samples have to match up perfectly without margin for error results in significantly less false positives.
I've found that when the algorithm is actually stuck energy fluctuations are bascially non-existent, therefore I'm able to get away with these strict requirements.

Once detected, a stagnation is resolved by \href{https://en.wikipedia.org/wiki/Perturbation_theory}{perturbation}\textsuperscript{[16]}.
In essence this means randomly making a pre-specified amount of moves not taking into account if the move is an overall benifit or detriment to the solution,
in an attempt to escape local minima.

The perturbation amount must be defined in function of $n$, since using a constant wouldn't scale.
This could be defined as something static such as $\frac{n}{4}$,
but this way you increase the chances of wasting computation time the closer a stagnation occurs towards the end
since you now have higher chances of wasting multiple carefully calculated correct queen placements each perturbation.

A pragmatic method for resolving this potential waste of resources is by calculating the perturbation amount dynamically using a modified version of SA.
Instead of using temperature, this version is based on the ratio of the total board energy compared to the energy at the start of the entire problem.
The closer the current board energy is to the start, the more agressive the algorithm is. By being more gentle toward the end,
there is much less chance of losing a good board setup and having to start over.

\[
    p = \left\lceil p_{min}+\frac{E_{current}}{E_{begin}} \left(p_{max} - p_{min}\right)\right\rceil
\]

Where:

\begin{itemize}
    \item $\mathbf{p}$: calculated amount of perturbations
    \item $\mathbf{p_{min}}$: minimum amount of perturbations
    \item $\mathbf{p_{max}}$: maximum amount of perturbations
    \item $\mathbf{E_{begin}}$: board energy at initialization
    \item $\mathbf{E_{current}}$: current board energy
\end{itemize}

The formula calculates \( p \) as a linear interpolation between \( p_{\text{min}} \) and \( p_{\text{max}} \),
based on the ratio of \( E_{\text{current}} \) to \( E_{\text{begin}} \).
As the current energy level \( E_{\text{current}} \) approaches the initial energy level \( E_{\text{begin}} \),
\( p \) approaches \( p_{\text{max}} \).
Conversely, if \( E_{\text{current}} \) is low, \( p \) will be closer to \( p_{\text{min}} \).
The ceiling function ensures that \( p \) is rounded up to the next integer so that always at least one perturbation will occur.


In practice the following numbers were used:
\[
    p = \left\lceil 1+\frac{E_{current}}{E_{begin}} \left(\frac{n}{10} - 1\right)\right\rceil
\]

As previously stated, even when $E\to0$, a positive stagnation check will result in at least one perturbation so that an attempt to solve the stagnation is always made,
and at most $\frac{n}{10}$ perturbations.
Making too many alterations to the board, e.g. $\frac{n}{4}$, is detrimental to the carefully computed board min-conflicts has constructed.
Local minima in later stages can be escaped by smaller, non-overzealous perturbations.

Following is the C++ implementation of this formula:

\begin{lstlisting}
    for (int i = 0; i < ceil(1.0 + (static_cast<double>(E_board) / E_begin) * (n / 10.0 - 1.0)); ++i) {
        // perform perturbation
    }
\end{lstlisting}

\subsubsection{Critical Issue 2: Initial Convergence}
The second large problem is initial convergence. In other words going from the initial energy of the arbitrary starting board (e.g. $E=1800$)
to a lower energy which min-conflicts can comfortably work with (e.g. $E=100$).

This isn't a big issue with smaller $n$ but as $n \to 1000$ this starts getting very time-consuming.
Enough so that this algorithm is incapable of solving \texttt{nQueens(1000)} withing the given time constraint of 160000 ms, making this a critical issue.

Although there are many possible solutions for this issue, after a large amount trial-and-error,
I settled on altering the function which generated the starting layout arbitrarily to make use of a heuristic so that it creates
a starting-board with energy-levels much closer to the eventual solution.

The heuristic which was selected to be impelemented is the \href{https://en.wikipedia.org/wiki/Greedy_algorithm}{greedy algorithm}\textsuperscript{[17]} heuristic.
Basically by making locally-optimal choices, choices which only serve to minimize energy at that moment and not globally,
the algorithm can place the queens such that the starting energy is much more managable.

Implementation initially caused a spike in stagnations and average execution times since this approach eliminated any randomness
but concequently also caused the solution space to be less effectively explored. The simple solution for this minor issue was to introduce a small amount of randomness
into the function.

Since this function didn't seem to be named I've dubbed it "gan-init" (Greedy-Random Initialization).

Gan-init exponentially improved average execution times causing me to mark this issue as solved.

\subsection{On the Computation of E}
The $E$-value or energy of a queen is the amount of conflicts that specific queen currently has with other queens, in other words,
how many other queens she can attack from her current position. How a queen can attack is defined in
\href{https://en.wikipedia.org/wiki/Queen_(chess)\#Placement\_and\_movement}{the rules of chess}\textsuperscript{[18]}.

To compute E, the following methods were utilised:

\clearpage
\subsubsection{Line Indexing}
In a matrix (such as a chessboard), each diagonal, anti-diagonal, horizontal, and vertical line can be given an index, which could be seen as a name of sorts.

E.g. following is a table constructed using the formula $i = x-y$ to illustrate the concept of indexed diagonals:

\[
    \begin{array}{c|cccccccc}
                   & \mathbf{0} & \mathbf{1} & \mathbf{2} & \mathbf{3} & \mathbf{4} & \mathbf{5} & \mathbf{n} & x \rightarrow \\
        \hline
        \mathbf{0} & 0          & 1          & 2          & 3          & 4          & 5          & \cdots                     \\
        \mathbf{1} & -1         & 0          & 1          & 2          & 3          & 4          & \cdots                     \\
        \mathbf{2} & -2         & -1         & 0          & 1          & 2          & 3          & \cdots                     \\
        \mathbf{3} & -3         & -2         & -1         & 0          & 1          & 2          & \cdots                     \\
        \mathbf{4} & -4         & -3         & -2         & -1         & 0          & 1          & \cdots                     \\
        \mathbf{5} & -5         & -4         & -3         & -2         & -1         & 0          & \cdots                     \\
        \mathbf{n} & \vdots     & \vdots     & \vdots     & \vdots     & \vdots     & \vdots     & \ddots                     \\
        y \downarrow                                                                                                          \\
    \end{array}
\]


As seen above, diagonals can be indexed or "named" e.g. "$-1$" or "$3$".
By using this concept, you can compute if any diagonals or horizontals are being shared relatively cheaply.

\subsubsection{Datatype}
Due to the nature of this problem, a valid solution means that there can be only one queen per row, so there is no need to represent the chessboard with an actual 2D-array.
The datatype to represent the board is defined as follows:

\begin{lstlisting}
using Board = std::vector<int>;
\end{lstlisting}

This C++ code defines a list of integers as a new datatype named "\texttt{Board}".

This way, the index of the array represents the row, and the value represents the column.
Limiting a queen's movements to one column also significantly improves the chances of a change being productive.
This cuts the number of required comparisons per queen per iteration by a factor of $n$.

\subsubsection{Calculation}
Using these insights, definitions and formulas can be constructed.
A conflict is defined as:
\[
    conflict = \left(b[i] = b[j]\right) \lor \left( \left|b[i] - b[j]\right| = \left|i - j\right|\right)
\]
Where $b = \texttt{Board}$ (zero-indexed) and $[$  $]$, indexing operator.

\clearpage
Using the definition of a conflict, a formula to compute the board's total energy can be constructed:

\[
    E_{board} = \sum_{i=0}^{n-1} \sum_{j=i+1}^{n-1} \left[ (b[j] = b[i]) \lor \left( \left| b[i] - b[j] \right| = \left| i - j \right| \right) \right]
\]

This formula iterates over all pairs $(i, j)$ where $i, j \in \mathbb{Z}^+$, $i \leq n \land j \leq n$.
If this pair satisfies one of the constraints, $E$ is incremented by one.
Per pair, one and only one constraint can be satisfied at a time, so there is no loss in accuracy by compressing all constraints into one large constraint.

Following is the C++ implementation of the energy formulae:

\begin{lstlisting}
  inline int calculateBoardE(const Board& b) {
  const int n = static_cast<int>(b.size())-1; // Get board size (n)
  int E = 0; // start with E := 0
  for (int i = 0; i < n; ++i) {
    // Dont count i == j
    for (int j = i + 1; j < n; ++j) {
      // if (not in same col) or (not in same diagonal)
      // row doesn't need to be checked since the code doesn't allow two queens to generate in one row.
      if (b[i] == b[j] || std::abs(b[i] - b[j]) == std::abs(i - j)) {
        ++E; // increment E
      }
    }
  }
  return E;
}
\end{lstlisting}

\subsection{Final Constraints}
Since the algorithm was now capable of efficiently calculating n-Queens with large $n$ in a timely manner,
there were a few more constraints to be handeled order to comply with the problem definition.

\subsubsection{Base Cases}
Base cases are cases in which the algorithm is not applicable or cannot be used in order to determine the result based on the given arguments.

\begin{itemize}
    \item $\boldsymbol{n = 1}$: Trivial solution. Only one location so only one queen possible. Only one queen so no possible attacks.
          Handle by always returning a queen in cell $(0, 0)$.
    \item $\boldsymbol{\{ n \in \mathbbm{Z} \mid n < 4 \land n \neq 1\}}$: No solutions possible. Handle by always returning failiure.
\end{itemize}

\clearpage
\subsubsection{Mandatory Queen}
The problem definition specifies an argument:

\begin{lstlisting}
std::pair<int mandatoryRow, int mandatoryColumn>
\end{lstlisting}

This C++ code can be translated as: "a pair $(x, y)$ which specifies the location for a queen which must be present in the final solution."
This is mostly there to increase the difficulty of the problem, as it introduces new challenges and considerations.

To implement this, one can simply modify \texttt{gan-init()} to place the mandatory queen as the first queen and then construct the initial board around that queen.
For min-conflicts, you simply skip the row where the mandatory queen is located so that it doesn't get included in any lists and, by extension, doesn't get altered.

The problem this causes is that now, especially for smaller boards where \(4 \leq n \leq 7\),
you can have queen placements that block all possible solutions. These so-called "queen-blockades" cannot be resolved.
In other words, they must be detected and the appropriate response for "invalid" has to be returned.

For example, there are only two valid configurations for \(n = 4\):
\begin{center}
    \begin{minipage}{0.45\textwidth}
        \centering
        \[
            \textbf{Solution 1:}
        \]
        \renewcommand{\arraystretch}{2}
        \begin{tabular}{|c|c|c|c|}
            \hline
                                      &                           & $\mathbf{Q}_{\mathbf{3}}$ &                           \\
            \hline
            $\mathbf{Q}_{\mathbf{1}}$ &                           &                           &                           \\
            \hline
                                      &                           &                           & $\mathbf{Q}_{\mathbf{4}}$ \\
            \hline
                                      & $\mathbf{Q}_{\mathbf{2}}$ &                           &                           \\
            \hline
        \end{tabular}
        \renewcommand{\arraystretch}{1} % Reset to default value

        \[
            [(0, 1), (1, 3), (2, 0), (3, 2)]
        \]
    \end{minipage}
    \hspace{0.05\textwidth}
    \begin{minipage}{0.45\textwidth}
        \centering
        \[
            \textbf{Solution 2:}
        \]
        \renewcommand{\arraystretch}{2}
        \begin{tabular}{|c|c|c|c|}
            \hline
                                      & $\mathbf{Q}_{\mathbf{2}}$ &                           &                           \\
            \hline
                                      &                           &                           & $\mathbf{Q}_{\mathbf{4}}$ \\
            \hline
            $\mathbf{Q}_{\mathbf{1}}$ &                           &                           &                           \\
            \hline
                                      &                           & $\mathbf{Q}_{\mathbf{3}}$ &                           \\
            \hline
        \end{tabular}
        \renewcommand{\arraystretch}{1} % Reset to default value

        \[
            [(0, 2), (1, 0), (2, 3), (3, 1)]
        \]
    \end{minipage}
\end{center}

If a mandatory queen position does not match any of these positions, that queen will block any possible solution.
Thus, the appropriate response for "invalid" has to be returned.

The best way to detect if any given input is valid is by examining the \(iterationCount\).
Due to earlier test-suite results, the average number of iterations for any given \(n\) is known.
Thus, it is only a matter of introducing a stopping mechanism whenever the algorithm exceeds the average number of iterations
plus some extra margin to minimize false negatives in case of very bad luck.

\subsection{Conclusion}
Although pure min-conflicts isn't able to handle this problem, by implementing the modifications and solutions outlined above,
this method is very efficient at computing the n-Queens problem.

\clearpage

\section*{References}
In case you are viewing a printed version of this document and cannot click on the embedded links, the URLs are provided below for manual entry:

\sloppy

\begin{enumerate}
    \item Algorithmic backtracking: \url{https://en.wikipedia.org/wiki/Backtracking}
    \item Time complexity: \url{https://en.wikipedia.org/wiki/Time_complexity}
    \item Decision tree pruning: \url{https://en.wikipedia.org/wiki/Decision_tree_pruning}
    \item Memoization: \url{https://en.wikipedia.org/wiki/Memoization}
    \item Symmetry reduction: \url{https://www.khoury.northeastern.edu/home/wahl/Publications/ew05b.pdf}
    \item Simulated Annealing: \url{https://en.wikipedia.org/wiki/Simulated_annealing}
    \item Randomized algorithm: \url{https://en.wikipedia.org/wiki/Randomized_algorithm}
    \item Metaheuristic: \url{https://en.wikipedia.org/wiki/Metaheuristic}
    \item Metallurgy: \url{https://en.wikipedia.org/wiki/Metallurgy}
    \item Entropy: \url{https://en.wikipedia.org/wiki/Entropy}
    \item Constraint Satisfaction Problem: \url{https://en.wikipedia.org/wiki/Constraint\_satisfaction\_problem}
    \item Brute-force attack: \url{https://en.wikipedia.org/wiki/Brute-force_attack}
    \item Euler's number: \url{https://en.wikipedia.org/wiki/E_(mathematical_constant)}
    \item Travelling Salesman Problem: \url{https://en.wikipedia.org/wiki/Travelling_salesman_problem}
    \item Min-Conflicts algorithm: \url{https://en.wikipedia.org/wiki/Min-conflicts_algorithm}
    \item Perturbation: \url{https://en.wikipedia.org/wiki/Perturbation_theory}
    \item Greedy algorithm: \url{https://en.wikipedia.org/wiki/Greedy_algorithm}
    \item Queen movement rules: \url{https://en.wikipedia.org/wiki/Queen_(chess)\#Placement\_and\_movement}
\end{enumerate}

\end{document}